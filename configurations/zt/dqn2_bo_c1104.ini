[DQN]
### experiment ###
PRE_TRAIN_MODEL_FILE
GPU_INDEX = 1
;PRE_TRAIN_MODEL_FILE = /home/zhangtao/model_file/hello_rl/dqn2__breakout_20181002_095208_20181002_165827.model
;PRE_TRAIN_MODEL_FILE = D:\data\\rl\\model\\net_c1004_dqn_20180914_084702_20180918_214237.model
EPOCH_NUM = 360
EPOCH_LENGTH = 30000
PLAYER_NUM = 7


### game env ###
# GAME_NAME = riverraid
GAME_NAME = breakout
ACTION_NUM = 4
OBSERVATION_TYPE = image
CHANNEL = 3
WIDTH = 160
HEIGHT = 210
FRAME_SKIP = 4
# FRAME_SKIP = 8

### player ###
RANDOM_EPISODE_PER_PLAYER = 10
EPSILON_MIN = 0.15
EPSILON_START = 1.0
EPSILON_DECAY = 150000
FILTER_EXPERIENCE = True


### replay buffer ###
PHI_LENGTH = 4
;PHI_LENGTH = 12
BUFFER_MAX = 100000
;BUFFER_MAX = 100000
BEGIN_RANDOM_STEP = 1000


### Coach ###
PLAY_NET_UPDATE_INTERVAL = 20
TARGET_NET_UPDATE_INTERVAL = 500
POLICY_NET_SAVE_INTERVAL = 9000
COACH_STAT_RANGE = 100

### q-learning ###
DISCOUNT = 0.90
BATCH_SIZE = 64



;OPTIMIZER = adam
OPTIMIZER = adagrad
LEARNING_RATE = 0.005
WEIGHT_DECAY = 0.0
GRAD_CLIPPING_THETA = 0.01

POSITIVE_REWARD = 0.05
NEGATIVE_REWARD = -1

### OTHER ###
MODEL_PATH = /home/zhangtao/model_file/hello_rl
FILE_PREFIX = dqn2_04

EDITED_TIME = 2018-10-05 20:58